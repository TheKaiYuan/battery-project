{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "battery json data  convert to matrix and input to CNN for train，没有容量特征字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from scipy.io import loadmat, whosmat\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "# 获取得到 json data of battery \n",
    "def json_load(dictonary):\n",
    "    with open(dictonary) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "'''\n",
    "cycle为行数，循环读取一行数据，对一行数据里面的voltage,current and temp求均值，并添加capacity features\n",
    "得到battery array\n",
    "'''\n",
    "def batteryData2array(battery_data):\n",
    "    vol_sum = 0\n",
    "    cur_sum = 0\n",
    "    temp_sum=0\n",
    "    battery_array = []\n",
    "    for cycle in battery_data.keys():\n",
    "        # list type \n",
    "        battery_vols = battery_data[cycle][\"voltage_battery\"]\n",
    "        battery_curs = battery_data[cycle][\"current_battery\"]\n",
    "        battery_temps=battery_data[cycle][\"temp_battery\"]\n",
    "        battery_capacity=battery_data[cycle][\"Capacity\"]\n",
    "        for battery_vol in battery_vols:\n",
    "            vol_sum += float(battery_vol)\n",
    "        for battery_cur in battery_curs:\n",
    "            cur_sum += float(battery_cur)\n",
    "        for battery_temp in battery_temps:\n",
    "            temp_sum += float(battery_temp)\n",
    "        #for voltage and current average  & battery_vols,battery_curs,battery_temps's len is equal\n",
    "        num = len(battery_vols)\n",
    "        vol_aver = vol_sum / num\n",
    "        cur_aver = cur_sum / num\n",
    "        temp_aver=temp_sum/num\n",
    "        vol_sum = 0\n",
    "        cur_sum = 0\n",
    "        temp_sum=0\n",
    "        battery_array.append([vol_aver,cur_aver,temp_aver])\n",
    "#         battery_array.append([vol_aver,cur_aver,battery_capacity[0]])\n",
    "    return battery_array\n",
    "\n",
    "# get battery's true soc\n",
    "def  getTrueSOC(battery_discharge_data):\n",
    "    batteryCapcity=2\n",
    "    soc_dict=[]\n",
    "    for cycle in battery_discharge_data.keys():\n",
    "        cycleCapacity=battery_discharge_data[cycle][\"Capacity\"]\n",
    "        soc_true=cycleCapacity[0]/batteryCapcity\n",
    "        soc_dict.append(soc_true)\n",
    "    return soc_dict\n",
    "\n",
    "# get battery's discgarge capacity\n",
    "def  getTrueCapacity(battery_discharge_data):\n",
    "    capacity=[]\n",
    "    for cycle in battery_discharge_data.keys():\n",
    "        cycleCapacity=battery_discharge_data[cycle][\"Capacity\"]\n",
    "        capacity.append(cycleCapacity[0])\n",
    "    return capacity\n",
    "\n",
    "'''\n",
    "获取得到 battery 's img matrix 图像矩阵  4维特征向量  vol_aver,cur_aver,temp_aver,battery_capacity\n",
    "返回battery discharge matrix and true soc array\n",
    "'''\n",
    "def batterydata2matrix(discharge):\n",
    "    #get the discharge and charge json data\n",
    "    discharge_data =json_load(discharge)\n",
    "    \n",
    "    #get the true soc data\n",
    "    true_soc=getTrueSOC(discharge_data)\n",
    "#   true_capacity=getTrueCapacity(discharge_data)\n",
    "    #get the battery discharge array data  convert to matrix\n",
    "    discharge_array = batteryData2array(discharge_data)\n",
    "    discharge_matrix = np.array(discharge_array)\n",
    "\n",
    "    discharge_matrix=preprocessing.scale(discharge_matrix)\n",
    "    return discharge_matrix,true_soc\n",
    "\n",
    "'''\n",
    "获取得到每一节电池数据的训练数据集\n",
    "得到train & test data\n",
    "'''\n",
    "def getTrainData(discharge_matrix,true_soc):     \n",
    "    #循环切片形成数据集\n",
    "    x=[];y=[]\n",
    "    x_train=[];y_train=[]\n",
    "    flag=0\n",
    "\n",
    "    # 获取得到x,y的数据集\n",
    "    for i in range(len(discharge_matrix.tolist())):\n",
    "        #首先截取长度为8的矩阵，叠加循环得到x\n",
    "        bataery_data_training=discharge_matrix[flag:flag+8,:]\n",
    "    #     print(bataery_data_training.shape)\n",
    "        if(len(bataery_data_training)<8):\n",
    "            break\n",
    "        else:\n",
    "            #进行转置，形成4*T的时间维度\n",
    "            x.append(bataery_data_training.T)\n",
    "        flag+=1\n",
    "    #0-》t时刻d x 预测得到t时刻的soc。为了对soc 进行预测，y矩阵为【7：】\n",
    "    y=true_soc[7:]\n",
    "#     y=true_capacity[8:]\n",
    "\n",
    "    VALIDATION_SPLIT=0.9\n",
    "    x_validation_samples = int( VALIDATION_SPLIT* len(x))\n",
    "    y_validation_samples = int( VALIDATION_SPLIT*len(y))\n",
    "    \n",
    "    \n",
    "    # 获取得到训练集，验证集，比例9:1\n",
    "    x_train=np.array(x[:x_validation_samples])\n",
    "    x_test=np.array(x[x_validation_samples:])\n",
    "    y_train=np.array(y[:y_validation_samples])\n",
    "    y_test=np.array(y[y_validation_samples:])\n",
    "    print(\"x_train's shape is:\", x_train.shape,\"，y_train's shape is:\",y_train.shape)\n",
    "    print(\"x_test's shape is:\",x_test.shape,\"，y_test's shape is:\",y_test.shape)\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train's shape is: (144, 3, 8) ，y_train's shape is: (144,)\n",
      "x_test's shape is: (17, 3, 8) ，y_test's shape is: (17,)\n",
      "x_train's shape is: (144, 3, 8) ，y_train's shape is: (144,)\n",
      "x_test's shape is: (17, 3, 8) ，y_test's shape is: (17,)\n",
      "x_train's shape is: (144, 3, 8) ，y_train's shape is: (144,)\n",
      "x_test's shape is: (17, 3, 8) ，y_test's shape is: (17,)\n",
      "(432, 3, 8) (51, 3, 8) (432,) (51,)\n"
     ]
    }
   ],
   "source": [
    "# 定义全局变量，将所有电池数据集集合起来，形成训练集，测试集\n",
    "# x_train_all,x_test_all,y_train_all,y_test_all=[],[],[],[]\n",
    "for i in range(5,8):\n",
    "    #/home/aqts/yangHong/battery experiment/jsonData\n",
    "    discharge=r'/home/aqts/yangHong/battery experiment/jsonData/B000'+str(i)+'_discharge.json'\n",
    "    discharge_matrix,true_soc=batterydata2matrix(discharge)\n",
    "    train_x,test_x,train_y,test_y=getTrainData(discharge_matrix,true_soc)\n",
    "    # start 开始时先赋值给x_train_all，x_test_all，y_train_all，y_test_all\n",
    "    if i==5:\n",
    "        x_train_all=train_x\n",
    "        x_test_all=test_x\n",
    "        y_train_all=train_y\n",
    "        y_test_all=test_y\n",
    "    else:\n",
    "        x_train_all=np.concatenate((x_train_all,train_x),axis=0)\n",
    "        x_test_all=np.concatenate((x_test_all,test_x),axis=0)\n",
    "        y_train_all=np.concatenate((y_train_all,train_y),axis=0)\n",
    "        y_test_all=np.concatenate((y_test_all,test_y),axis=0)\n",
    "print(np.array(x_train_all).shape,np.array(x_test_all).shape,np.array(y_train_all).shape,np.array(y_test_all).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aqts/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#写一个LossHistory类，保存loss和mae\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,Convolution2D\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('mean_absolute_error'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_mean_absolute_error'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('mean_absolute_error'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_mean_absolute_error'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # mae\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train mae')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_mean_absolute_error\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val mean absolute error')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('mae-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于序贯(Sequential)编程方式的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_235 (Conv2D)          (None, 3, 8, 64)          192       \n",
      "_________________________________________________________________\n",
      "conv2d_236 (Conv2D)          (None, 3, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 1, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_237 (Conv2D)          (None, 1, 4, 64)          16448     \n",
      "_________________________________________________________________\n",
      "conv2d_238 (Conv2D)          (None, 1, 4, 64)          16448     \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "gaussian_noise_7 (GaussianNo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 70,673\n",
      "Trainable params: 70,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 302 samples, validate on 130 samples\n",
      "Epoch 1/128\n",
      "302/302 [==============================] - 4s 13ms/step - loss: 0.4300 - mean_absolute_error: 0.5852 - val_loss: 0.1554 - val_mean_absolute_error: 0.3181\n",
      "Epoch 2/128\n",
      "302/302 [==============================] - 0s 631us/step - loss: 0.1230 - mean_absolute_error: 0.2315 - val_loss: 0.0607 - val_mean_absolute_error: 0.0870\n",
      "Epoch 3/128\n",
      "302/302 [==============================] - 0s 627us/step - loss: 0.0789 - mean_absolute_error: 0.1352 - val_loss: 0.0541 - val_mean_absolute_error: 0.0483\n",
      "Epoch 4/128\n",
      "302/302 [==============================] - 0s 650us/step - loss: 0.0735 - mean_absolute_error: 0.1184 - val_loss: 0.0539 - val_mean_absolute_error: 0.0435\n",
      "Epoch 5/128\n",
      "302/302 [==============================] - 0s 638us/step - loss: 0.0713 - mean_absolute_error: 0.1119 - val_loss: 0.0537 - val_mean_absolute_error: 0.0427\n",
      "Epoch 6/128\n",
      "302/302 [==============================] - 0s 657us/step - loss: 0.0718 - mean_absolute_error: 0.1160 - val_loss: 0.0535 - val_mean_absolute_error: 0.0424\n",
      "Epoch 7/128\n",
      "302/302 [==============================] - 0s 625us/step - loss: 0.0721 - mean_absolute_error: 0.1155 - val_loss: 0.0534 - val_mean_absolute_error: 0.0406\n",
      "Epoch 8/128\n",
      "302/302 [==============================] - 0s 684us/step - loss: 0.0712 - mean_absolute_error: 0.1144 - val_loss: 0.0532 - val_mean_absolute_error: 0.0397\n",
      "Epoch 9/128\n",
      "302/302 [==============================] - 0s 631us/step - loss: 0.0691 - mean_absolute_error: 0.1083 - val_loss: 0.0530 - val_mean_absolute_error: 0.0387\n",
      "Epoch 10/128\n",
      "302/302 [==============================] - 0s 630us/step - loss: 0.0715 - mean_absolute_error: 0.1151 - val_loss: 0.0530 - val_mean_absolute_error: 0.0387\n",
      "Epoch 11/128\n",
      "302/302 [==============================] - 0s 676us/step - loss: 0.0710 - mean_absolute_error: 0.1124 - val_loss: 0.0527 - val_mean_absolute_error: 0.0372\n",
      "Epoch 12/128\n",
      "302/302 [==============================] - 0s 657us/step - loss: 0.0703 - mean_absolute_error: 0.1126 - val_loss: 0.0525 - val_mean_absolute_error: 0.0361\n",
      "Epoch 13/128\n",
      "302/302 [==============================] - 0s 664us/step - loss: 0.0680 - mean_absolute_error: 0.1068 - val_loss: 0.0524 - val_mean_absolute_error: 0.0355\n",
      "Epoch 14/128\n",
      "302/302 [==============================] - 0s 674us/step - loss: 0.0682 - mean_absolute_error: 0.1052 - val_loss: 0.0524 - val_mean_absolute_error: 0.0353\n",
      "Epoch 15/128\n",
      "302/302 [==============================] - 0s 658us/step - loss: 0.0669 - mean_absolute_error: 0.1025 - val_loss: 0.0522 - val_mean_absolute_error: 0.0344\n",
      "Epoch 16/128\n",
      "302/302 [==============================] - 0s 654us/step - loss: 0.0684 - mean_absolute_error: 0.1060 - val_loss: 0.0521 - val_mean_absolute_error: 0.0334\n",
      "Epoch 17/128\n",
      "302/302 [==============================] - 0s 660us/step - loss: 0.0672 - mean_absolute_error: 0.1021 - val_loss: 0.0520 - val_mean_absolute_error: 0.0330\n",
      "Epoch 18/128\n",
      "302/302 [==============================] - 0s 659us/step - loss: 0.0678 - mean_absolute_error: 0.1043 - val_loss: 0.0519 - val_mean_absolute_error: 0.0325\n",
      "Epoch 19/128\n",
      "302/302 [==============================] - 0s 649us/step - loss: 0.0655 - mean_absolute_error: 0.0990 - val_loss: 0.0521 - val_mean_absolute_error: 0.0349\n",
      "Epoch 20/128\n",
      "302/302 [==============================] - 0s 659us/step - loss: 0.0681 - mean_absolute_error: 0.1054 - val_loss: 0.0518 - val_mean_absolute_error: 0.0327\n",
      "Epoch 21/128\n",
      "302/302 [==============================] - 0s 642us/step - loss: 0.0654 - mean_absolute_error: 0.0976 - val_loss: 0.0516 - val_mean_absolute_error: 0.0311\n",
      "Epoch 22/128\n",
      "302/302 [==============================] - 0s 652us/step - loss: 0.0664 - mean_absolute_error: 0.1039 - val_loss: 0.0515 - val_mean_absolute_error: 0.0307\n",
      "Epoch 23/128\n",
      "302/302 [==============================] - 0s 641us/step - loss: 0.0657 - mean_absolute_error: 0.1013 - val_loss: 0.0515 - val_mean_absolute_error: 0.0314\n",
      "Epoch 24/128\n",
      "302/302 [==============================] - 0s 657us/step - loss: 0.0655 - mean_absolute_error: 0.1000 - val_loss: 0.0514 - val_mean_absolute_error: 0.0298\n",
      "Epoch 25/128\n",
      "302/302 [==============================] - 0s 614us/step - loss: 0.0657 - mean_absolute_error: 0.0988 - val_loss: 0.0513 - val_mean_absolute_error: 0.0295\n",
      "Epoch 26/128\n",
      "302/302 [==============================] - 0s 644us/step - loss: 0.0635 - mean_absolute_error: 0.0932 - val_loss: 0.0513 - val_mean_absolute_error: 0.0302\n",
      "Epoch 27/128\n",
      "302/302 [==============================] - 0s 643us/step - loss: 0.0661 - mean_absolute_error: 0.1023 - val_loss: 0.0511 - val_mean_absolute_error: 0.0290\n",
      "Epoch 28/128\n",
      "302/302 [==============================] - 0s 659us/step - loss: 0.0642 - mean_absolute_error: 0.0944 - val_loss: 0.0511 - val_mean_absolute_error: 0.0296\n",
      "Epoch 29/128\n",
      "302/302 [==============================] - 0s 639us/step - loss: 0.0635 - mean_absolute_error: 0.0955 - val_loss: 0.0513 - val_mean_absolute_error: 0.0317\n",
      "Epoch 30/128\n",
      "302/302 [==============================] - 0s 616us/step - loss: 0.0620 - mean_absolute_error: 0.0866 - val_loss: 0.0511 - val_mean_absolute_error: 0.0300\n",
      "Epoch 31/128\n",
      "302/302 [==============================] - 0s 662us/step - loss: 0.0639 - mean_absolute_error: 0.0950 - val_loss: 0.0510 - val_mean_absolute_error: 0.0303\n",
      "Epoch 32/128\n",
      "302/302 [==============================] - 0s 665us/step - loss: 0.0614 - mean_absolute_error: 0.0855 - val_loss: 0.0508 - val_mean_absolute_error: 0.0278\n",
      "Epoch 33/128\n",
      "302/302 [==============================] - 0s 647us/step - loss: 0.0608 - mean_absolute_error: 0.0830 - val_loss: 0.0508 - val_mean_absolute_error: 0.0281\n",
      "Epoch 34/128\n",
      "302/302 [==============================] - 0s 634us/step - loss: 0.0623 - mean_absolute_error: 0.0875 - val_loss: 0.0507 - val_mean_absolute_error: 0.0278\n",
      "Epoch 35/128\n",
      "302/302 [==============================] - 0s 628us/step - loss: 0.0635 - mean_absolute_error: 0.0938 - val_loss: 0.0507 - val_mean_absolute_error: 0.0280\n",
      "Epoch 36/128\n",
      "302/302 [==============================] - 0s 645us/step - loss: 0.0601 - mean_absolute_error: 0.0832 - val_loss: 0.0507 - val_mean_absolute_error: 0.0289\n",
      "Epoch 37/128\n",
      "302/302 [==============================] - 0s 674us/step - loss: 0.0590 - mean_absolute_error: 0.0789 - val_loss: 0.0507 - val_mean_absolute_error: 0.0290\n",
      "Epoch 38/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 657us/step - loss: 0.0593 - mean_absolute_error: 0.0797 - val_loss: 0.0506 - val_mean_absolute_error: 0.0287\n",
      "Epoch 39/128\n",
      "302/302 [==============================] - 0s 652us/step - loss: 0.0605 - mean_absolute_error: 0.0836 - val_loss: 0.0506 - val_mean_absolute_error: 0.0286\n",
      "Epoch 40/128\n",
      "302/302 [==============================] - 0s 678us/step - loss: 0.0623 - mean_absolute_error: 0.0908 - val_loss: 0.0504 - val_mean_absolute_error: 0.0275\n",
      "Epoch 41/128\n",
      "302/302 [==============================] - 0s 660us/step - loss: 0.0618 - mean_absolute_error: 0.0875 - val_loss: 0.0504 - val_mean_absolute_error: 0.0269\n",
      "Epoch 42/128\n",
      "302/302 [==============================] - 0s 645us/step - loss: 0.0606 - mean_absolute_error: 0.0827 - val_loss: 0.0505 - val_mean_absolute_error: 0.0292\n",
      "Epoch 43/128\n",
      "302/302 [==============================] - 0s 640us/step - loss: 0.0598 - mean_absolute_error: 0.0827 - val_loss: 0.0503 - val_mean_absolute_error: 0.0277\n",
      "Epoch 44/128\n",
      "302/302 [==============================] - 0s 636us/step - loss: 0.0590 - mean_absolute_error: 0.0778 - val_loss: 0.0504 - val_mean_absolute_error: 0.0287\n",
      "Epoch 45/128\n",
      "302/302 [==============================] - 0s 644us/step - loss: 0.0599 - mean_absolute_error: 0.0793 - val_loss: 0.0503 - val_mean_absolute_error: 0.0282\n",
      "Epoch 46/128\n",
      "302/302 [==============================] - 0s 638us/step - loss: 0.0607 - mean_absolute_error: 0.0849 - val_loss: 0.0502 - val_mean_absolute_error: 0.0273\n",
      "Epoch 47/128\n",
      "302/302 [==============================] - 0s 667us/step - loss: 0.0597 - mean_absolute_error: 0.0830 - val_loss: 0.0502 - val_mean_absolute_error: 0.0278\n",
      "Epoch 48/128\n",
      "302/302 [==============================] - 0s 670us/step - loss: 0.0579 - mean_absolute_error: 0.0724 - val_loss: 0.0502 - val_mean_absolute_error: 0.0278\n",
      "Epoch 49/128\n",
      "302/302 [==============================] - 0s 648us/step - loss: 0.0591 - mean_absolute_error: 0.0800 - val_loss: 0.0502 - val_mean_absolute_error: 0.0284\n",
      "Epoch 50/128\n",
      "302/302 [==============================] - 0s 651us/step - loss: 0.0600 - mean_absolute_error: 0.0844 - val_loss: 0.0502 - val_mean_absolute_error: 0.0293\n",
      "Epoch 51/128\n",
      "302/302 [==============================] - 0s 685us/step - loss: 0.0571 - mean_absolute_error: 0.0723 - val_loss: 0.0501 - val_mean_absolute_error: 0.0285\n",
      "Epoch 52/128\n",
      "302/302 [==============================] - 0s 629us/step - loss: 0.0584 - mean_absolute_error: 0.0774 - val_loss: 0.0499 - val_mean_absolute_error: 0.0272\n",
      "Epoch 53/128\n",
      "302/302 [==============================] - 0s 659us/step - loss: 0.0584 - mean_absolute_error: 0.0769 - val_loss: 0.0499 - val_mean_absolute_error: 0.0272\n",
      "Epoch 54/128\n",
      "302/302 [==============================] - 0s 646us/step - loss: 0.0579 - mean_absolute_error: 0.0728 - val_loss: 0.0499 - val_mean_absolute_error: 0.0275\n",
      "Epoch 55/128\n",
      "302/302 [==============================] - 0s 641us/step - loss: 0.0583 - mean_absolute_error: 0.0750 - val_loss: 0.0498 - val_mean_absolute_error: 0.0273\n",
      "Epoch 56/128\n",
      "302/302 [==============================] - 0s 631us/step - loss: 0.0577 - mean_absolute_error: 0.0732 - val_loss: 0.0498 - val_mean_absolute_error: 0.0271\n",
      "Epoch 57/128\n",
      "302/302 [==============================] - 0s 655us/step - loss: 0.0578 - mean_absolute_error: 0.0752 - val_loss: 0.0498 - val_mean_absolute_error: 0.0275\n",
      "Epoch 58/128\n",
      "302/302 [==============================] - 0s 682us/step - loss: 0.0577 - mean_absolute_error: 0.0754 - val_loss: 0.0497 - val_mean_absolute_error: 0.0275\n",
      "Epoch 59/128\n",
      "302/302 [==============================] - 0s 672us/step - loss: 0.0586 - mean_absolute_error: 0.0794 - val_loss: 0.0497 - val_mean_absolute_error: 0.0270\n",
      "Epoch 60/128\n",
      "302/302 [==============================] - 0s 611us/step - loss: 0.0572 - mean_absolute_error: 0.0715 - val_loss: 0.0496 - val_mean_absolute_error: 0.0269\n",
      "Epoch 61/128\n",
      "302/302 [==============================] - 0s 620us/step - loss: 0.0568 - mean_absolute_error: 0.0709 - val_loss: 0.0496 - val_mean_absolute_error: 0.0269\n",
      "Epoch 62/128\n",
      "302/302 [==============================] - 0s 589us/step - loss: 0.0578 - mean_absolute_error: 0.0765 - val_loss: 0.0496 - val_mean_absolute_error: 0.0274\n",
      "Epoch 63/128\n",
      "302/302 [==============================] - 0s 636us/step - loss: 0.0573 - mean_absolute_error: 0.0756 - val_loss: 0.0496 - val_mean_absolute_error: 0.0274\n",
      "Epoch 64/128\n",
      "302/302 [==============================] - 0s 635us/step - loss: 0.0556 - mean_absolute_error: 0.0670 - val_loss: 0.0495 - val_mean_absolute_error: 0.0271\n",
      "Epoch 65/128\n",
      "302/302 [==============================] - 0s 620us/step - loss: 0.0560 - mean_absolute_error: 0.0691 - val_loss: 0.0494 - val_mean_absolute_error: 0.0268\n",
      "Epoch 66/128\n",
      "302/302 [==============================] - 0s 624us/step - loss: 0.0561 - mean_absolute_error: 0.0703 - val_loss: 0.0494 - val_mean_absolute_error: 0.0268\n",
      "Epoch 67/128\n",
      "302/302 [==============================] - 0s 600us/step - loss: 0.0559 - mean_absolute_error: 0.0686 - val_loss: 0.0495 - val_mean_absolute_error: 0.0285\n",
      "Epoch 68/128\n",
      "302/302 [==============================] - 0s 596us/step - loss: 0.0559 - mean_absolute_error: 0.0702 - val_loss: 0.0495 - val_mean_absolute_error: 0.0293\n",
      "Epoch 69/128\n",
      "302/302 [==============================] - 0s 563us/step - loss: 0.0558 - mean_absolute_error: 0.0687 - val_loss: 0.0495 - val_mean_absolute_error: 0.0290\n",
      "Epoch 70/128\n",
      "302/302 [==============================] - 0s 589us/step - loss: 0.0573 - mean_absolute_error: 0.0752 - val_loss: 0.0493 - val_mean_absolute_error: 0.0282\n",
      "Epoch 71/128\n",
      "302/302 [==============================] - 0s 621us/step - loss: 0.0557 - mean_absolute_error: 0.0676 - val_loss: 0.0492 - val_mean_absolute_error: 0.0271\n",
      "Epoch 72/128\n",
      "302/302 [==============================] - 0s 582us/step - loss: 0.0563 - mean_absolute_error: 0.0724 - val_loss: 0.0493 - val_mean_absolute_error: 0.0288\n",
      "Epoch 73/128\n",
      "302/302 [==============================] - 0s 630us/step - loss: 0.0553 - mean_absolute_error: 0.0664 - val_loss: 0.0493 - val_mean_absolute_error: 0.0291\n",
      "Epoch 74/128\n",
      "302/302 [==============================] - 0s 630us/step - loss: 0.0556 - mean_absolute_error: 0.0685 - val_loss: 0.0492 - val_mean_absolute_error: 0.0286\n",
      "Epoch 75/128\n",
      "302/302 [==============================] - 0s 623us/step - loss: 0.0564 - mean_absolute_error: 0.0707 - val_loss: 0.0490 - val_mean_absolute_error: 0.0263\n",
      "Epoch 76/128\n",
      "302/302 [==============================] - 0s 622us/step - loss: 0.0556 - mean_absolute_error: 0.0692 - val_loss: 0.0490 - val_mean_absolute_error: 0.0266\n",
      "Epoch 77/128\n",
      "302/302 [==============================] - 0s 601us/step - loss: 0.0556 - mean_absolute_error: 0.0690 - val_loss: 0.0490 - val_mean_absolute_error: 0.0268\n",
      "Epoch 78/128\n",
      "302/302 [==============================] - 0s 623us/step - loss: 0.0552 - mean_absolute_error: 0.0645 - val_loss: 0.0490 - val_mean_absolute_error: 0.0279\n",
      "Epoch 79/128\n",
      "302/302 [==============================] - 0s 634us/step - loss: 0.0549 - mean_absolute_error: 0.0670 - val_loss: 0.0491 - val_mean_absolute_error: 0.0293\n",
      "Epoch 80/128\n",
      "302/302 [==============================] - 0s 612us/step - loss: 0.0546 - mean_absolute_error: 0.0652 - val_loss: 0.0489 - val_mean_absolute_error: 0.0278\n",
      "Epoch 81/128\n",
      "302/302 [==============================] - 0s 590us/step - loss: 0.0553 - mean_absolute_error: 0.0682 - val_loss: 0.0489 - val_mean_absolute_error: 0.0279\n",
      "Epoch 82/128\n",
      "302/302 [==============================] - 0s 600us/step - loss: 0.0551 - mean_absolute_error: 0.0681 - val_loss: 0.0489 - val_mean_absolute_error: 0.0279\n",
      "Epoch 83/128\n",
      "302/302 [==============================] - 0s 626us/step - loss: 0.0554 - mean_absolute_error: 0.0694 - val_loss: 0.0488 - val_mean_absolute_error: 0.0270\n",
      "Epoch 84/128\n",
      "302/302 [==============================] - 0s 623us/step - loss: 0.0559 - mean_absolute_error: 0.0733 - val_loss: 0.0488 - val_mean_absolute_error: 0.0279\n",
      "Epoch 85/128\n",
      "302/302 [==============================] - 0s 610us/step - loss: 0.0553 - mean_absolute_error: 0.0681 - val_loss: 0.0488 - val_mean_absolute_error: 0.0281\n",
      "Epoch 86/128\n",
      "302/302 [==============================] - 0s 605us/step - loss: 0.0554 - mean_absolute_error: 0.0723 - val_loss: 0.0489 - val_mean_absolute_error: 0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/128\n",
      "302/302 [==============================] - 0s 617us/step - loss: 0.0544 - mean_absolute_error: 0.0642 - val_loss: 0.0488 - val_mean_absolute_error: 0.0299\n",
      "Epoch 88/128\n",
      "302/302 [==============================] - 0s 649us/step - loss: 0.0543 - mean_absolute_error: 0.0622 - val_loss: 0.0489 - val_mean_absolute_error: 0.0308\n",
      "Epoch 89/128\n",
      "302/302 [==============================] - 0s 624us/step - loss: 0.0542 - mean_absolute_error: 0.0659 - val_loss: 0.0488 - val_mean_absolute_error: 0.0311\n",
      "Epoch 90/128\n",
      "302/302 [==============================] - 0s 640us/step - loss: 0.0548 - mean_absolute_error: 0.0683 - val_loss: 0.0488 - val_mean_absolute_error: 0.0309\n",
      "Epoch 91/128\n",
      "302/302 [==============================] - 0s 639us/step - loss: 0.0534 - mean_absolute_error: 0.0619 - val_loss: 0.0489 - val_mean_absolute_error: 0.0327\n",
      "Epoch 92/128\n",
      "302/302 [==============================] - 0s 625us/step - loss: 0.0531 - mean_absolute_error: 0.0597 - val_loss: 0.0487 - val_mean_absolute_error: 0.0303\n",
      "Epoch 93/128\n",
      "302/302 [==============================] - 0s 602us/step - loss: 0.0538 - mean_absolute_error: 0.0638 - val_loss: 0.0487 - val_mean_absolute_error: 0.0307\n",
      "Epoch 94/128\n",
      "302/302 [==============================] - 0s 609us/step - loss: 0.0538 - mean_absolute_error: 0.0632 - val_loss: 0.0486 - val_mean_absolute_error: 0.0306\n",
      "Epoch 95/128\n",
      "302/302 [==============================] - 0s 622us/step - loss: 0.0543 - mean_absolute_error: 0.0646 - val_loss: 0.0486 - val_mean_absolute_error: 0.0311\n",
      "Epoch 96/128\n",
      "302/302 [==============================] - 0s 645us/step - loss: 0.0544 - mean_absolute_error: 0.0652 - val_loss: 0.0487 - val_mean_absolute_error: 0.0328\n",
      "Epoch 97/128\n",
      "302/302 [==============================] - 0s 619us/step - loss: 0.0535 - mean_absolute_error: 0.0620 - val_loss: 0.0485 - val_mean_absolute_error: 0.0307\n",
      "Epoch 98/128\n",
      "302/302 [==============================] - 0s 616us/step - loss: 0.0525 - mean_absolute_error: 0.0567 - val_loss: 0.0485 - val_mean_absolute_error: 0.0314\n",
      "Epoch 99/128\n",
      "302/302 [==============================] - 0s 640us/step - loss: 0.0543 - mean_absolute_error: 0.0659 - val_loss: 0.0486 - val_mean_absolute_error: 0.0331\n",
      "Epoch 100/128\n",
      "302/302 [==============================] - 0s 624us/step - loss: 0.0532 - mean_absolute_error: 0.0609 - val_loss: 0.0487 - val_mean_absolute_error: 0.0344\n",
      "Epoch 101/128\n",
      "302/302 [==============================] - 0s 623us/step - loss: 0.0530 - mean_absolute_error: 0.0601 - val_loss: 0.0485 - val_mean_absolute_error: 0.0322\n",
      "Epoch 102/128\n",
      "302/302 [==============================] - 0s 608us/step - loss: 0.0529 - mean_absolute_error: 0.0614 - val_loss: 0.0484 - val_mean_absolute_error: 0.0320\n",
      "Epoch 103/128\n",
      "302/302 [==============================] - 0s 622us/step - loss: 0.0527 - mean_absolute_error: 0.0601 - val_loss: 0.0485 - val_mean_absolute_error: 0.0338\n",
      "Epoch 104/128\n",
      "302/302 [==============================] - 0s 624us/step - loss: 0.0534 - mean_absolute_error: 0.0625 - val_loss: 0.0485 - val_mean_absolute_error: 0.0336\n",
      "Epoch 105/128\n",
      "302/302 [==============================] - 0s 632us/step - loss: 0.0536 - mean_absolute_error: 0.0654 - val_loss: 0.0485 - val_mean_absolute_error: 0.0336\n",
      "Epoch 106/128\n",
      "302/302 [==============================] - 0s 602us/step - loss: 0.0530 - mean_absolute_error: 0.0631 - val_loss: 0.0483 - val_mean_absolute_error: 0.0322\n",
      "Epoch 107/128\n",
      "302/302 [==============================] - 0s 667us/step - loss: 0.0524 - mean_absolute_error: 0.0571 - val_loss: 0.0482 - val_mean_absolute_error: 0.0319\n",
      "Epoch 108/128\n",
      "302/302 [==============================] - 0s 602us/step - loss: 0.0525 - mean_absolute_error: 0.0596 - val_loss: 0.0482 - val_mean_absolute_error: 0.0318\n",
      "Epoch 109/128\n",
      "302/302 [==============================] - 0s 571us/step - loss: 0.0522 - mean_absolute_error: 0.0592 - val_loss: 0.0483 - val_mean_absolute_error: 0.0336\n",
      "Epoch 110/128\n",
      "302/302 [==============================] - 0s 600us/step - loss: 0.0517 - mean_absolute_error: 0.0538 - val_loss: 0.0483 - val_mean_absolute_error: 0.0342\n",
      "Epoch 111/128\n",
      "302/302 [==============================] - 0s 608us/step - loss: 0.0527 - mean_absolute_error: 0.0603 - val_loss: 0.0484 - val_mean_absolute_error: 0.0351\n",
      "Epoch 112/128\n",
      "302/302 [==============================] - 0s 578us/step - loss: 0.0521 - mean_absolute_error: 0.0581 - val_loss: 0.0483 - val_mean_absolute_error: 0.0351\n",
      "Epoch 113/128\n",
      "302/302 [==============================] - 0s 581us/step - loss: 0.0519 - mean_absolute_error: 0.0560 - val_loss: 0.0483 - val_mean_absolute_error: 0.0352\n",
      "Epoch 114/128\n",
      "302/302 [==============================] - 0s 575us/step - loss: 0.0524 - mean_absolute_error: 0.0617 - val_loss: 0.0483 - val_mean_absolute_error: 0.0363\n",
      "Epoch 115/128\n",
      "302/302 [==============================] - 0s 516us/step - loss: 0.0523 - mean_absolute_error: 0.0594 - val_loss: 0.0483 - val_mean_absolute_error: 0.0361\n",
      "Epoch 116/128\n",
      "302/302 [==============================] - 0s 593us/step - loss: 0.0516 - mean_absolute_error: 0.0578 - val_loss: 0.0482 - val_mean_absolute_error: 0.0358\n",
      "Epoch 117/128\n",
      "302/302 [==============================] - 0s 613us/step - loss: 0.0528 - mean_absolute_error: 0.0625 - val_loss: 0.0481 - val_mean_absolute_error: 0.0352\n",
      "Epoch 118/128\n",
      "302/302 [==============================] - 0s 620us/step - loss: 0.0525 - mean_absolute_error: 0.0608 - val_loss: 0.0481 - val_mean_absolute_error: 0.0354\n",
      "Epoch 119/128\n",
      "302/302 [==============================] - 0s 613us/step - loss: 0.0518 - mean_absolute_error: 0.0571 - val_loss: 0.0483 - val_mean_absolute_error: 0.0373\n",
      "Epoch 120/128\n",
      "302/302 [==============================] - 0s 618us/step - loss: 0.0526 - mean_absolute_error: 0.0621 - val_loss: 0.0482 - val_mean_absolute_error: 0.0374\n",
      "Epoch 121/128\n",
      "302/302 [==============================] - 0s 645us/step - loss: 0.0526 - mean_absolute_error: 0.0619 - val_loss: 0.0481 - val_mean_absolute_error: 0.0370\n",
      "Epoch 122/128\n",
      "302/302 [==============================] - 0s 634us/step - loss: 0.0516 - mean_absolute_error: 0.0573 - val_loss: 0.0483 - val_mean_absolute_error: 0.0386\n",
      "Epoch 123/128\n",
      "302/302 [==============================] - 0s 628us/step - loss: 0.0517 - mean_absolute_error: 0.0586 - val_loss: 0.0483 - val_mean_absolute_error: 0.0395\n",
      "Epoch 124/128\n",
      "302/302 [==============================] - 0s 619us/step - loss: 0.0513 - mean_absolute_error: 0.0565 - val_loss: 0.0480 - val_mean_absolute_error: 0.0369\n",
      "Epoch 125/128\n",
      "302/302 [==============================] - 0s 613us/step - loss: 0.0515 - mean_absolute_error: 0.0561 - val_loss: 0.0481 - val_mean_absolute_error: 0.0386\n",
      "Epoch 126/128\n",
      "302/302 [==============================] - 0s 608us/step - loss: 0.0515 - mean_absolute_error: 0.0565 - val_loss: 0.0481 - val_mean_absolute_error: 0.0386\n",
      "Epoch 127/128\n",
      "302/302 [==============================] - 0s 609us/step - loss: 0.0523 - mean_absolute_error: 0.0592 - val_loss: 0.0479 - val_mean_absolute_error: 0.0370\n",
      "Epoch 128/128\n",
      "302/302 [==============================] - 0s 668us/step - loss: 0.0518 - mean_absolute_error: 0.0597 - val_loss: 0.0478 - val_mean_absolute_error: 0.0363\n",
      "Test MSE Score:5.047 %\n",
      "Test MAE Score:5.141 %\n"
     ]
    }
   ],
   "source": [
    "#使用cnn训练的模型\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,Convolution2D,GRU,LSTM\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.layers.noise import GaussianNoise\n",
    "# 引用GPU命令\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "num=1\n",
    "img_rows, img_cols =x_train_all.shape[1],x_train_all.shape[2]\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    x_train_all = x_train_all.reshape(x_train_all.shape[0], 1, img_rows, img_cols)\n",
    "    x_test_all = x_test_all.reshape(x_test_all.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train_all = x_train_all.reshape(x_train_all.shape[0], img_rows, img_cols, 1)\n",
    "    x_test_all= x_test_all.reshape(x_test_all.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "# lstm_layer=(None, input_shape[0], input_shape[1], input_shape[2])\n",
    "# print(x_train.shape,x_test.shape)\n",
    "# print(y_train.shape)\n",
    "# keras序贯模型搭建CNN\n",
    "# model building\n",
    "model = Sequential()\n",
    "\n",
    "#convolutional layer with rectified linear unit activation\n",
    "model.add(Conv2D(64, kernel_size=(1,2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,padding=\"same\"))\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "model.add(Conv2D(128, (2,2), activation='relu',padding=\"same\"))\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, (2,1), activation='relu',padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(64, (2,2), activation='relu',padding=\"same\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# GaussianNoise\n",
    "# model.add(GaussianNoise(stddev=0.01))\n",
    "#fully connected to get all relevant data\n",
    "model.add(Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(GaussianNoise(stddev=0.1))\n",
    "\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# model.add(Dense(num, activation='sigmoid'))\n",
    "# The last layer does not use the activation function\n",
    "model.add(Dense(num))\n",
    "\n",
    "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n",
    "#categorical ce since we have multiple classes (10) \n",
    "# model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "#回归问题评价指标使用mae\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mse', optimizer=\"sgd\", metrics=[\"mae\"])\n",
    "\n",
    "model.summary()\n",
    "batch_size =16\n",
    "num_epoch = 128\n",
    "\n",
    "\n",
    "\n",
    "# decay_rate = learning_rate / num_epoch\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# model.compile(loss='mse', optimizer=sgd, metrics=[\"mae\"])\n",
    "#model training\n",
    "history2= LossHistory()\n",
    "model.fit(x_train_all, y_train_all,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,validation_split=0.3,callbacks=[history2])\n",
    "\n",
    "mse_score,mae_score= model.evaluate(x_test_all, y_test_all, verbose=0)\n",
    "print('Test MSE Score:%.3f %%'% (mse_score*100)) \n",
    "print('Test MAE Score:%.3f %%'% (mae_score*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将CNN模型使用函数式编程的模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 3, 8, 64)          192       \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 3, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 1, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 1, 4, 32)          8224      \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 1, 4, 64)          8256      \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 51,785\n",
      "Trainable params: 51,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 302 samples, validate on 130 samples\n",
      "Epoch 1/128\n",
      "302/302 [==============================] - 3s 11ms/step - loss: 0.4487 - mean_absolute_error: 0.6431 - val_loss: 0.2764 - val_mean_absolute_error: 0.5063\n",
      "Epoch 2/128\n",
      "302/302 [==============================] - 0s 561us/step - loss: 0.1707 - mean_absolute_error: 0.3750 - val_loss: 0.1102 - val_mean_absolute_error: 0.3001\n",
      "Epoch 3/128\n",
      "302/302 [==============================] - 0s 570us/step - loss: 0.0729 - mean_absolute_error: 0.2133 - val_loss: 0.0514 - val_mean_absolute_error: 0.1768\n",
      "Epoch 4/128\n",
      "302/302 [==============================] - 0s 576us/step - loss: 0.0446 - mean_absolute_error: 0.1349 - val_loss: 0.0312 - val_mean_absolute_error: 0.1050\n",
      "Epoch 5/128\n",
      "302/302 [==============================] - 0s 601us/step - loss: 0.0334 - mean_absolute_error: 0.1080 - val_loss: 0.0249 - val_mean_absolute_error: 0.0756\n",
      "Epoch 6/128\n",
      "302/302 [==============================] - 0s 551us/step - loss: 0.0302 - mean_absolute_error: 0.1027 - val_loss: 0.0225 - val_mean_absolute_error: 0.0662\n",
      "Epoch 7/128\n",
      "302/302 [==============================] - 0s 568us/step - loss: 0.0307 - mean_absolute_error: 0.1050 - val_loss: 0.0215 - val_mean_absolute_error: 0.0623\n",
      "Epoch 8/128\n",
      "302/302 [==============================] - 0s 574us/step - loss: 0.0292 - mean_absolute_error: 0.0984 - val_loss: 0.0212 - val_mean_absolute_error: 0.0612\n",
      "Epoch 9/128\n",
      "302/302 [==============================] - 0s 564us/step - loss: 0.0288 - mean_absolute_error: 0.0988 - val_loss: 0.0211 - val_mean_absolute_error: 0.0608\n",
      "Epoch 10/128\n",
      "302/302 [==============================] - 0s 571us/step - loss: 0.0302 - mean_absolute_error: 0.1035 - val_loss: 0.0208 - val_mean_absolute_error: 0.0599\n",
      "Epoch 11/128\n",
      "302/302 [==============================] - 0s 564us/step - loss: 0.0283 - mean_absolute_error: 0.0992 - val_loss: 0.0208 - val_mean_absolute_error: 0.0598\n",
      "Epoch 12/128\n",
      "302/302 [==============================] - 0s 559us/step - loss: 0.0296 - mean_absolute_error: 0.1024 - val_loss: 0.0207 - val_mean_absolute_error: 0.0595\n",
      "Epoch 13/128\n",
      "302/302 [==============================] - 0s 565us/step - loss: 0.0285 - mean_absolute_error: 0.0984 - val_loss: 0.0206 - val_mean_absolute_error: 0.0591\n",
      "Epoch 14/128\n",
      "302/302 [==============================] - 0s 578us/step - loss: 0.0287 - mean_absolute_error: 0.1011 - val_loss: 0.0204 - val_mean_absolute_error: 0.0579\n",
      "Epoch 15/128\n",
      "302/302 [==============================] - 0s 558us/step - loss: 0.0270 - mean_absolute_error: 0.0943 - val_loss: 0.0201 - val_mean_absolute_error: 0.0566\n",
      "Epoch 16/128\n",
      "302/302 [==============================] - 0s 589us/step - loss: 0.0273 - mean_absolute_error: 0.0934 - val_loss: 0.0200 - val_mean_absolute_error: 0.0558\n",
      "Epoch 17/128\n",
      "302/302 [==============================] - 0s 564us/step - loss: 0.0261 - mean_absolute_error: 0.0913 - val_loss: 0.0198 - val_mean_absolute_error: 0.0541\n",
      "Epoch 18/128\n",
      "302/302 [==============================] - 0s 555us/step - loss: 0.0268 - mean_absolute_error: 0.0913 - val_loss: 0.0197 - val_mean_absolute_error: 0.0529\n",
      "Epoch 19/128\n",
      "302/302 [==============================] - 0s 555us/step - loss: 0.0272 - mean_absolute_error: 0.0929 - val_loss: 0.0196 - val_mean_absolute_error: 0.0516\n",
      "Epoch 20/128\n",
      "302/302 [==============================] - 0s 550us/step - loss: 0.0261 - mean_absolute_error: 0.0889 - val_loss: 0.0192 - val_mean_absolute_error: 0.0492\n",
      "Epoch 21/128\n",
      "302/302 [==============================] - 0s 568us/step - loss: 0.0250 - mean_absolute_error: 0.0857 - val_loss: 0.0188 - val_mean_absolute_error: 0.0468\n",
      "Epoch 22/128\n",
      "302/302 [==============================] - 0s 583us/step - loss: 0.0247 - mean_absolute_error: 0.0826 - val_loss: 0.0188 - val_mean_absolute_error: 0.0463\n",
      "Epoch 23/128\n",
      "302/302 [==============================] - 0s 553us/step - loss: 0.0248 - mean_absolute_error: 0.0824 - val_loss: 0.0184 - val_mean_absolute_error: 0.0437\n",
      "Epoch 24/128\n",
      "302/302 [==============================] - 0s 534us/step - loss: 0.0240 - mean_absolute_error: 0.0781 - val_loss: 0.0183 - val_mean_absolute_error: 0.0428\n",
      "Epoch 25/128\n",
      "302/302 [==============================] - 0s 540us/step - loss: 0.0235 - mean_absolute_error: 0.0770 - val_loss: 0.0181 - val_mean_absolute_error: 0.0417\n",
      "Epoch 26/128\n",
      "302/302 [==============================] - 0s 512us/step - loss: 0.0224 - mean_absolute_error: 0.0715 - val_loss: 0.0179 - val_mean_absolute_error: 0.0404\n",
      "Epoch 27/128\n",
      "302/302 [==============================] - 0s 547us/step - loss: 0.0240 - mean_absolute_error: 0.0759 - val_loss: 0.0177 - val_mean_absolute_error: 0.0389\n",
      "Epoch 28/128\n",
      "302/302 [==============================] - 0s 502us/step - loss: 0.0219 - mean_absolute_error: 0.0676 - val_loss: 0.0179 - val_mean_absolute_error: 0.0412\n",
      "Epoch 29/128\n",
      "302/302 [==============================] - 0s 528us/step - loss: 0.0226 - mean_absolute_error: 0.0696 - val_loss: 0.0177 - val_mean_absolute_error: 0.0402\n",
      "Epoch 30/128\n",
      "302/302 [==============================] - 0s 557us/step - loss: 0.0225 - mean_absolute_error: 0.0677 - val_loss: 0.0175 - val_mean_absolute_error: 0.0389\n",
      "Epoch 31/128\n",
      "302/302 [==============================] - 0s 565us/step - loss: 0.0218 - mean_absolute_error: 0.0668 - val_loss: 0.0172 - val_mean_absolute_error: 0.0363\n",
      "Epoch 32/128\n",
      "302/302 [==============================] - 0s 573us/step - loss: 0.0215 - mean_absolute_error: 0.0634 - val_loss: 0.0171 - val_mean_absolute_error: 0.0357\n",
      "Epoch 33/128\n",
      "302/302 [==============================] - 0s 580us/step - loss: 0.0230 - mean_absolute_error: 0.0700 - val_loss: 0.0170 - val_mean_absolute_error: 0.0346\n",
      "Epoch 34/128\n",
      "302/302 [==============================] - 0s 576us/step - loss: 0.0213 - mean_absolute_error: 0.0615 - val_loss: 0.0171 - val_mean_absolute_error: 0.0369\n",
      "Epoch 35/128\n",
      "302/302 [==============================] - 0s 557us/step - loss: 0.0201 - mean_absolute_error: 0.0563 - val_loss: 0.0170 - val_mean_absolute_error: 0.0365\n",
      "Epoch 36/128\n",
      "302/302 [==============================] - 0s 578us/step - loss: 0.0210 - mean_absolute_error: 0.0615 - val_loss: 0.0168 - val_mean_absolute_error: 0.0338\n",
      "Epoch 37/128\n",
      "302/302 [==============================] - 0s 566us/step - loss: 0.0218 - mean_absolute_error: 0.0642 - val_loss: 0.0166 - val_mean_absolute_error: 0.0324\n",
      "Epoch 38/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 548us/step - loss: 0.0202 - mean_absolute_error: 0.0551 - val_loss: 0.0167 - val_mean_absolute_error: 0.0336\n",
      "Epoch 39/128\n",
      "302/302 [==============================] - 0s 553us/step - loss: 0.0207 - mean_absolute_error: 0.0593 - val_loss: 0.0166 - val_mean_absolute_error: 0.0326\n",
      "Epoch 40/128\n",
      "302/302 [==============================] - 0s 574us/step - loss: 0.0211 - mean_absolute_error: 0.0590 - val_loss: 0.0166 - val_mean_absolute_error: 0.0333\n",
      "Epoch 41/128\n",
      "302/302 [==============================] - 0s 566us/step - loss: 0.0211 - mean_absolute_error: 0.0609 - val_loss: 0.0164 - val_mean_absolute_error: 0.0304\n",
      "Epoch 42/128\n",
      "302/302 [==============================] - 0s 590us/step - loss: 0.0201 - mean_absolute_error: 0.0553 - val_loss: 0.0165 - val_mean_absolute_error: 0.0331\n",
      "Epoch 43/128\n",
      "302/302 [==============================] - 0s 581us/step - loss: 0.0208 - mean_absolute_error: 0.0588 - val_loss: 0.0166 - val_mean_absolute_error: 0.0346\n",
      "Epoch 44/128\n",
      "302/302 [==============================] - 0s 583us/step - loss: 0.0203 - mean_absolute_error: 0.0556 - val_loss: 0.0164 - val_mean_absolute_error: 0.0323\n",
      "Epoch 45/128\n",
      "302/302 [==============================] - 0s 542us/step - loss: 0.0197 - mean_absolute_error: 0.0537 - val_loss: 0.0165 - val_mean_absolute_error: 0.0347\n",
      "Epoch 46/128\n",
      "302/302 [==============================] - 0s 607us/step - loss: 0.0203 - mean_absolute_error: 0.0544 - val_loss: 0.0163 - val_mean_absolute_error: 0.0323\n",
      "Epoch 47/128\n",
      "302/302 [==============================] - 0s 570us/step - loss: 0.0200 - mean_absolute_error: 0.0535 - val_loss: 0.0163 - val_mean_absolute_error: 0.0326\n",
      "Epoch 48/128\n",
      "302/302 [==============================] - 0s 585us/step - loss: 0.0203 - mean_absolute_error: 0.0557 - val_loss: 0.0162 - val_mean_absolute_error: 0.0315\n",
      "Epoch 49/128\n",
      "302/302 [==============================] - 0s 565us/step - loss: 0.0189 - mean_absolute_error: 0.0494 - val_loss: 0.0166 - val_mean_absolute_error: 0.0369\n",
      "Epoch 50/128\n",
      "302/302 [==============================] - 0s 593us/step - loss: 0.0190 - mean_absolute_error: 0.0489 - val_loss: 0.0161 - val_mean_absolute_error: 0.0306\n",
      "Epoch 51/128\n",
      "302/302 [==============================] - 0s 552us/step - loss: 0.0195 - mean_absolute_error: 0.0510 - val_loss: 0.0160 - val_mean_absolute_error: 0.0284\n",
      "Epoch 52/128\n",
      "302/302 [==============================] - 0s 557us/step - loss: 0.0194 - mean_absolute_error: 0.0512 - val_loss: 0.0161 - val_mean_absolute_error: 0.0306\n",
      "Epoch 53/128\n",
      "302/302 [==============================] - 0s 561us/step - loss: 0.0195 - mean_absolute_error: 0.0528 - val_loss: 0.0160 - val_mean_absolute_error: 0.0296\n",
      "Epoch 54/128\n",
      "302/302 [==============================] - 0s 579us/step - loss: 0.0190 - mean_absolute_error: 0.0497 - val_loss: 0.0160 - val_mean_absolute_error: 0.0303\n",
      "Epoch 55/128\n",
      "302/302 [==============================] - 0s 510us/step - loss: 0.0194 - mean_absolute_error: 0.0499 - val_loss: 0.0161 - val_mean_absolute_error: 0.0310\n",
      "Epoch 56/128\n",
      "302/302 [==============================] - 0s 551us/step - loss: 0.0188 - mean_absolute_error: 0.0471 - val_loss: 0.0160 - val_mean_absolute_error: 0.0308\n",
      "Epoch 57/128\n",
      "302/302 [==============================] - 0s 560us/step - loss: 0.0189 - mean_absolute_error: 0.0476 - val_loss: 0.0160 - val_mean_absolute_error: 0.0301\n",
      "Epoch 58/128\n",
      "302/302 [==============================] - 0s 554us/step - loss: 0.0195 - mean_absolute_error: 0.0514 - val_loss: 0.0158 - val_mean_absolute_error: 0.0274\n",
      "Epoch 59/128\n",
      "302/302 [==============================] - 0s 538us/step - loss: 0.0195 - mean_absolute_error: 0.0520 - val_loss: 0.0158 - val_mean_absolute_error: 0.0278\n",
      "Epoch 60/128\n",
      "302/302 [==============================] - 0s 548us/step - loss: 0.0188 - mean_absolute_error: 0.0474 - val_loss: 0.0161 - val_mean_absolute_error: 0.0321\n",
      "Epoch 61/128\n",
      "302/302 [==============================] - 0s 537us/step - loss: 0.0192 - mean_absolute_error: 0.0510 - val_loss: 0.0161 - val_mean_absolute_error: 0.0333\n",
      "Epoch 62/128\n",
      "302/302 [==============================] - 0s 541us/step - loss: 0.0187 - mean_absolute_error: 0.0473 - val_loss: 0.0160 - val_mean_absolute_error: 0.0307\n",
      "Epoch 63/128\n",
      "302/302 [==============================] - 0s 545us/step - loss: 0.0186 - mean_absolute_error: 0.0456 - val_loss: 0.0160 - val_mean_absolute_error: 0.0321\n",
      "Epoch 64/128\n",
      "302/302 [==============================] - 0s 562us/step - loss: 0.0186 - mean_absolute_error: 0.0476 - val_loss: 0.0158 - val_mean_absolute_error: 0.0283\n",
      "Epoch 65/128\n",
      "302/302 [==============================] - 0s 529us/step - loss: 0.0184 - mean_absolute_error: 0.0457 - val_loss: 0.0160 - val_mean_absolute_error: 0.0314\n",
      "Epoch 66/128\n",
      "302/302 [==============================] - 0s 557us/step - loss: 0.0186 - mean_absolute_error: 0.0466 - val_loss: 0.0159 - val_mean_absolute_error: 0.0296\n",
      "Epoch 67/128\n",
      "302/302 [==============================] - 0s 546us/step - loss: 0.0184 - mean_absolute_error: 0.0457 - val_loss: 0.0159 - val_mean_absolute_error: 0.0314\n",
      "Epoch 68/128\n",
      "302/302 [==============================] - 0s 557us/step - loss: 0.0185 - mean_absolute_error: 0.0456 - val_loss: 0.0159 - val_mean_absolute_error: 0.0302\n",
      "Epoch 69/128\n",
      "302/302 [==============================] - 0s 561us/step - loss: 0.0186 - mean_absolute_error: 0.0466 - val_loss: 0.0157 - val_mean_absolute_error: 0.0272\n",
      "Epoch 70/128\n",
      "302/302 [==============================] - 0s 541us/step - loss: 0.0182 - mean_absolute_error: 0.0450 - val_loss: 0.0157 - val_mean_absolute_error: 0.0280\n",
      "Epoch 71/128\n",
      "302/302 [==============================] - 0s 559us/step - loss: 0.0180 - mean_absolute_error: 0.0432 - val_loss: 0.0158 - val_mean_absolute_error: 0.0294\n",
      "Epoch 72/128\n",
      "302/302 [==============================] - 0s 535us/step - loss: 0.0182 - mean_absolute_error: 0.0444 - val_loss: 0.0158 - val_mean_absolute_error: 0.0296\n",
      "Epoch 73/128\n",
      "302/302 [==============================] - 0s 549us/step - loss: 0.0188 - mean_absolute_error: 0.0499 - val_loss: 0.0158 - val_mean_absolute_error: 0.0307\n",
      "Epoch 74/128\n",
      "302/302 [==============================] - 0s 544us/step - loss: 0.0186 - mean_absolute_error: 0.0466 - val_loss: 0.0159 - val_mean_absolute_error: 0.0314\n",
      "Epoch 75/128\n",
      "302/302 [==============================] - 0s 544us/step - loss: 0.0183 - mean_absolute_error: 0.0455 - val_loss: 0.0158 - val_mean_absolute_error: 0.0302\n",
      "Epoch 76/128\n",
      "302/302 [==============================] - 0s 573us/step - loss: 0.0181 - mean_absolute_error: 0.0439 - val_loss: 0.0158 - val_mean_absolute_error: 0.0311\n",
      "Epoch 77/128\n",
      "302/302 [==============================] - 0s 559us/step - loss: 0.0179 - mean_absolute_error: 0.0429 - val_loss: 0.0156 - val_mean_absolute_error: 0.0276\n",
      "Epoch 78/128\n",
      "302/302 [==============================] - 0s 518us/step - loss: 0.0180 - mean_absolute_error: 0.0426 - val_loss: 0.0158 - val_mean_absolute_error: 0.0310\n",
      "Epoch 79/128\n",
      "302/302 [==============================] - 0s 554us/step - loss: 0.0184 - mean_absolute_error: 0.0457 - val_loss: 0.0157 - val_mean_absolute_error: 0.0302\n",
      "Epoch 80/128\n",
      "302/302 [==============================] - 0s 529us/step - loss: 0.0175 - mean_absolute_error: 0.0411 - val_loss: 0.0159 - val_mean_absolute_error: 0.0335\n",
      "Epoch 81/128\n",
      "302/302 [==============================] - 0s 570us/step - loss: 0.0180 - mean_absolute_error: 0.0434 - val_loss: 0.0158 - val_mean_absolute_error: 0.0317\n",
      "Epoch 82/128\n",
      "302/302 [==============================] - 0s 555us/step - loss: 0.0179 - mean_absolute_error: 0.0433 - val_loss: 0.0158 - val_mean_absolute_error: 0.0322\n",
      "Epoch 83/128\n",
      "302/302 [==============================] - 0s 558us/step - loss: 0.0176 - mean_absolute_error: 0.0420 - val_loss: 0.0157 - val_mean_absolute_error: 0.0308\n",
      "Epoch 84/128\n",
      "302/302 [==============================] - 0s 563us/step - loss: 0.0180 - mean_absolute_error: 0.0448 - val_loss: 0.0158 - val_mean_absolute_error: 0.0318\n",
      "Epoch 85/128\n",
      "302/302 [==============================] - 0s 551us/step - loss: 0.0177 - mean_absolute_error: 0.0410 - val_loss: 0.0158 - val_mean_absolute_error: 0.0316\n",
      "Epoch 86/128\n",
      "302/302 [==============================] - 0s 544us/step - loss: 0.0181 - mean_absolute_error: 0.0446 - val_loss: 0.0158 - val_mean_absolute_error: 0.0322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/128\n",
      "302/302 [==============================] - 0s 551us/step - loss: 0.0180 - mean_absolute_error: 0.0456 - val_loss: 0.0157 - val_mean_absolute_error: 0.0306\n",
      "Epoch 88/128\n",
      "302/302 [==============================] - 0s 554us/step - loss: 0.0176 - mean_absolute_error: 0.0425 - val_loss: 0.0156 - val_mean_absolute_error: 0.0292\n",
      "Epoch 89/128\n",
      "302/302 [==============================] - 0s 551us/step - loss: 0.0178 - mean_absolute_error: 0.0433 - val_loss: 0.0159 - val_mean_absolute_error: 0.0342\n",
      "Epoch 90/128\n",
      "302/302 [==============================] - 0s 548us/step - loss: 0.0177 - mean_absolute_error: 0.0429 - val_loss: 0.0155 - val_mean_absolute_error: 0.0274\n",
      "Epoch 91/128\n",
      "302/302 [==============================] - 0s 549us/step - loss: 0.0175 - mean_absolute_error: 0.0417 - val_loss: 0.0155 - val_mean_absolute_error: 0.0287\n",
      "Epoch 92/128\n",
      "302/302 [==============================] - 0s 550us/step - loss: 0.0178 - mean_absolute_error: 0.0443 - val_loss: 0.0155 - val_mean_absolute_error: 0.0292\n",
      "Epoch 93/128\n",
      "302/302 [==============================] - 0s 556us/step - loss: 0.0178 - mean_absolute_error: 0.0435 - val_loss: 0.0155 - val_mean_absolute_error: 0.0284\n",
      "Epoch 94/128\n",
      "302/302 [==============================] - 0s 532us/step - loss: 0.0174 - mean_absolute_error: 0.0400 - val_loss: 0.0156 - val_mean_absolute_error: 0.0298\n",
      "Epoch 95/128\n",
      "302/302 [==============================] - 0s 545us/step - loss: 0.0175 - mean_absolute_error: 0.0419 - val_loss: 0.0154 - val_mean_absolute_error: 0.0275\n",
      "Epoch 96/128\n",
      "302/302 [==============================] - 0s 542us/step - loss: 0.0174 - mean_absolute_error: 0.0418 - val_loss: 0.0156 - val_mean_absolute_error: 0.0302\n",
      "Epoch 97/128\n",
      "302/302 [==============================] - 0s 510us/step - loss: 0.0173 - mean_absolute_error: 0.0404 - val_loss: 0.0156 - val_mean_absolute_error: 0.0304\n",
      "Epoch 98/128\n",
      "302/302 [==============================] - 0s 537us/step - loss: 0.0171 - mean_absolute_error: 0.0390 - val_loss: 0.0157 - val_mean_absolute_error: 0.0323\n",
      "Epoch 99/128\n",
      "302/302 [==============================] - 0s 568us/step - loss: 0.0172 - mean_absolute_error: 0.0416 - val_loss: 0.0155 - val_mean_absolute_error: 0.0301\n",
      "Epoch 100/128\n",
      "302/302 [==============================] - 0s 548us/step - loss: 0.0169 - mean_absolute_error: 0.0389 - val_loss: 0.0155 - val_mean_absolute_error: 0.0299\n",
      "Epoch 101/128\n",
      "302/302 [==============================] - 0s 560us/step - loss: 0.0174 - mean_absolute_error: 0.0407 - val_loss: 0.0153 - val_mean_absolute_error: 0.0265\n",
      "Epoch 102/128\n",
      "302/302 [==============================] - 0s 549us/step - loss: 0.0177 - mean_absolute_error: 0.0419 - val_loss: 0.0154 - val_mean_absolute_error: 0.0292\n",
      "Epoch 103/128\n",
      "302/302 [==============================] - 0s 542us/step - loss: 0.0168 - mean_absolute_error: 0.0372 - val_loss: 0.0153 - val_mean_absolute_error: 0.0280\n",
      "Epoch 104/128\n",
      "302/302 [==============================] - 0s 520us/step - loss: 0.0176 - mean_absolute_error: 0.0440 - val_loss: 0.0154 - val_mean_absolute_error: 0.0287\n",
      "Epoch 105/128\n",
      "302/302 [==============================] - 0s 547us/step - loss: 0.0176 - mean_absolute_error: 0.0428 - val_loss: 0.0155 - val_mean_absolute_error: 0.0308\n",
      "Epoch 106/128\n",
      "302/302 [==============================] - 0s 531us/step - loss: 0.0169 - mean_absolute_error: 0.0385 - val_loss: 0.0156 - val_mean_absolute_error: 0.0324\n",
      "Epoch 107/128\n",
      "302/302 [==============================] - 0s 505us/step - loss: 0.0172 - mean_absolute_error: 0.0399 - val_loss: 0.0155 - val_mean_absolute_error: 0.0317\n",
      "Epoch 108/128\n",
      "302/302 [==============================] - 0s 514us/step - loss: 0.0171 - mean_absolute_error: 0.0396 - val_loss: 0.0154 - val_mean_absolute_error: 0.0303\n",
      "Epoch 109/128\n",
      "302/302 [==============================] - 0s 500us/step - loss: 0.0173 - mean_absolute_error: 0.0412 - val_loss: 0.0153 - val_mean_absolute_error: 0.0278\n",
      "Epoch 110/128\n",
      "302/302 [==============================] - 0s 510us/step - loss: 0.0167 - mean_absolute_error: 0.0375 - val_loss: 0.0153 - val_mean_absolute_error: 0.0280\n",
      "Epoch 111/128\n",
      "302/302 [==============================] - 0s 553us/step - loss: 0.0171 - mean_absolute_error: 0.0401 - val_loss: 0.0154 - val_mean_absolute_error: 0.0300\n",
      "Epoch 112/128\n",
      "302/302 [==============================] - 0s 521us/step - loss: 0.0178 - mean_absolute_error: 0.0457 - val_loss: 0.0154 - val_mean_absolute_error: 0.0297\n",
      "Epoch 113/128\n",
      "302/302 [==============================] - 0s 566us/step - loss: 0.0171 - mean_absolute_error: 0.0407 - val_loss: 0.0153 - val_mean_absolute_error: 0.0295\n",
      "Epoch 114/128\n",
      "302/302 [==============================] - 0s 529us/step - loss: 0.0171 - mean_absolute_error: 0.0406 - val_loss: 0.0153 - val_mean_absolute_error: 0.0285\n",
      "Epoch 115/128\n",
      "302/302 [==============================] - 0s 534us/step - loss: 0.0167 - mean_absolute_error: 0.0381 - val_loss: 0.0153 - val_mean_absolute_error: 0.0288\n",
      "Epoch 116/128\n",
      "302/302 [==============================] - 0s 544us/step - loss: 0.0169 - mean_absolute_error: 0.0384 - val_loss: 0.0153 - val_mean_absolute_error: 0.0295\n",
      "Epoch 117/128\n",
      "302/302 [==============================] - 0s 542us/step - loss: 0.0169 - mean_absolute_error: 0.0398 - val_loss: 0.0153 - val_mean_absolute_error: 0.0302\n",
      "Epoch 118/128\n",
      "302/302 [==============================] - 0s 517us/step - loss: 0.0166 - mean_absolute_error: 0.0366 - val_loss: 0.0153 - val_mean_absolute_error: 0.0304\n",
      "Epoch 119/128\n",
      "302/302 [==============================] - 0s 549us/step - loss: 0.0169 - mean_absolute_error: 0.0394 - val_loss: 0.0154 - val_mean_absolute_error: 0.0313\n",
      "Epoch 120/128\n",
      "302/302 [==============================] - 0s 545us/step - loss: 0.0169 - mean_absolute_error: 0.0393 - val_loss: 0.0153 - val_mean_absolute_error: 0.0303\n",
      "Epoch 121/128\n",
      "302/302 [==============================] - 0s 545us/step - loss: 0.0167 - mean_absolute_error: 0.0388 - val_loss: 0.0153 - val_mean_absolute_error: 0.0298\n",
      "Epoch 122/128\n",
      "302/302 [==============================] - 0s 526us/step - loss: 0.0169 - mean_absolute_error: 0.0401 - val_loss: 0.0152 - val_mean_absolute_error: 0.0283\n",
      "Epoch 123/128\n",
      "302/302 [==============================] - 0s 549us/step - loss: 0.0166 - mean_absolute_error: 0.0369 - val_loss: 0.0152 - val_mean_absolute_error: 0.0287\n",
      "Epoch 124/128\n",
      "302/302 [==============================] - 0s 562us/step - loss: 0.0168 - mean_absolute_error: 0.0379 - val_loss: 0.0150 - val_mean_absolute_error: 0.0265\n",
      "Epoch 125/128\n",
      "302/302 [==============================] - 0s 538us/step - loss: 0.0165 - mean_absolute_error: 0.0383 - val_loss: 0.0149 - val_mean_absolute_error: 0.0251\n",
      "Epoch 126/128\n",
      "302/302 [==============================] - 0s 533us/step - loss: 0.0168 - mean_absolute_error: 0.0387 - val_loss: 0.0152 - val_mean_absolute_error: 0.0299\n",
      "Epoch 127/128\n",
      "302/302 [==============================] - 0s 548us/step - loss: 0.0168 - mean_absolute_error: 0.0384 - val_loss: 0.0152 - val_mean_absolute_error: 0.0296\n",
      "Epoch 128/128\n",
      "302/302 [==============================] - 0s 531us/step - loss: 0.0164 - mean_absolute_error: 0.0370 - val_loss: 0.0152 - val_mean_absolute_error: 0.0303\n",
      "Test MSE Score:1.865 %\n",
      "Test MAE Score:5.217 %\n"
     ]
    }
   ],
   "source": [
    "# keras 函数时搭建cnn模型\n",
    "# model building\n",
    "lstm_input_shape=(nb_time_steps, nb_input_vector)\n",
    "cnn_main_input = Input(shape=input_shape, dtype='float32')\n",
    "lstm_main_input = Input(shape=lstm_input_shape, dtype='float32')\n",
    "#convolutional layer with rectified linear unit activation\n",
    "cnn=Conv2D(64, kernel_size=(1,2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,padding=\"same\")(cnn_main_input)\n",
    "cnn=Conv2D(128, (2,2), activation='relu',padding=\"same\")(cnn)\n",
    "cnn=MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "\n",
    "cnn=Conv2D(32, (2,1), activation='relu',padding=\"same\")(cnn)\n",
    "\n",
    "cnn=Conv2D(64, (2,2), activation='relu',padding=\"same\")(cnn)\n",
    "# cnn=MaxPooling2D(pool_size=(2, 2))(cnn)\n",
    "\n",
    "cnn=Flatten()(cnn)\n",
    "cnn=Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001))(cnn)\n",
    "cnn=Dropout(0.15)(cnn)\n",
    "\n",
    "cnn=Dense(16, activation='relu')(cnn)\n",
    "cnn=Dropout(0.10)(cnn)\n",
    "\n",
    "# rnn=LSTM(units=nb_lstm_outputs,dropout=0.4, recurrent_dropout=0.1,return_sequences=True)(lstm_main_input)\n",
    "# rnn=LSTM(64, dropout=0.4, recurrent_dropout=0.1)(rnn)\n",
    "\n",
    "# # two model connection\n",
    "# con = concatenate([cnn,rnn], axis=-1)\n",
    "main_output = Dense(num)(cnn)\n",
    "model = Model(inputs = cnn_main_input, outputs = main_output)\n",
    "model.compile(loss='mse', optimizer=\"sgd\", metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "batch_size =16\n",
    "num_epoch = 128\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# decay_rate = learning_rate / num_epoch\n",
    "# momentum = 0.8\n",
    "# sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "# model.compile(loss='mse', optimizer=sgd, metrics=[\"mae\"])\n",
    "#model training\n",
    "history = LossHistory()\n",
    "model.fit(x_train_all, y_train_all,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,validation_split=0.3,callbacks=[history])\n",
    "\n",
    "mse_score,mae_score= model.evaluate(x_test_all, y_test_all, verbose=0)\n",
    "print('Test MSE Score:%.3f %%'% (mse_score*100)) \n",
    "print('Test MAE Score:%.3f %%'% (mae_score*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naCUpREREK0khIiJa/wHUNrV2AG16bQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78c8ea26d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制mae-loss曲线\n",
    "history2.loss_plot('epoch')\n",
    "# input_shape[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取得到需要用于预测的电池数据集B0018号电池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_008 data shape is (125, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "# 获取预测所需的电池数据集\n",
    "def getBattery008data(discharge_matrix):\n",
    "    x_pred=[]\n",
    "    flag=0\n",
    "\n",
    "    # 获取得到x_pred的数据集\n",
    "    for i in range(len(discharge_matrix.tolist())):\n",
    "        #首先截取0--37这段的长度，叠加+1循环得到x\n",
    "        bataery_data_training=discharge_matrix[flag:flag+8,:]\n",
    "    #     print(bataery_data_training.shape)\n",
    "        if(len(bataery_data_training)<8):\n",
    "            break\n",
    "        else:\n",
    "            #进行转置，形成3*T的时间维度\n",
    "            x_pred.append(bataery_data_training.T)\n",
    "        flag+=1\n",
    "\n",
    "    x_pred=np.array(x_pred)\n",
    "    return x_pred\n",
    "\n",
    "# return prediction  data &  prediction  data true_so\n",
    "discharge_008=r'/home/aqts/yangHong/battery experiment/jsonData/B0008_discharge.json'\n",
    "# 获取得到一节电池的 特征向量 与true soc \n",
    "discharge_matrix_008,true_soc_008 =batterydata2matrix(discharge_008)\n",
    "# 得到预测样本集 t=7\n",
    "x_test_008=getBattery008data(discharge_matrix_008)\n",
    "\n",
    "\n",
    "print(\"x_test_008 data shape is\",x_test_008.shape)\n",
    "# 预测数据集进行转换\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    x_test_008 = x_test_008.reshape(x_test_008.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_test_008 = x_test_008.reshape(x_test_008.shape[0], img_rows, img_cols,1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 1)\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_test_008, batch_size=16, verbose=0)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_true_soc range is  range(0, 132) \n",
      " x_test_soc_008  range is: range(7, 132)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1PkfP0LTPAoFKZkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78c9ff4f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd # 导入pandas库用来处理csv文件\n",
    "import matplotlib.pyplot as plt # 导入matplotlib.pyplot并用plt简称\n",
    "\n",
    "# true soc predict plot\n",
    "x_true_soc=range(len(true_soc_008))\n",
    "# 切割开始的基数一定为7\n",
    "start=7\n",
    "x_test_soc_008=range(start,start+pred.shape[0])\n",
    "print(\"x_true_soc range is \",x_true_soc,\"\\n x_test_soc_008  range is:\",x_test_soc_008)\n",
    "plt.plot(x_true_soc, true_soc_008, linewidth=2.0, color='r',label=\"True SOC\")#线的宽度为2.0，颜色为红色\n",
    "plt.plot(x_test_soc_008, pred, linewidth=2.0, color='g',label=\"Prediction SOC\")#线的宽度为2.0，颜色为绿色\n",
    "\n",
    "\n",
    "# 设置x ,y轴的步长与刻度属性\n",
    "plt.xticks([x for x in range(len(x_true_soc) + 1) if x %10 == 0])  # x标记step设置为10\n",
    "plt.ylim(ymin=0.3,ymax=1.1)\n",
    "# remark for x & y\n",
    "plt.xlabel('Cylce')\n",
    "plt.ylabel('SOC')\n",
    "plt.title('Real Soc and Predicted Soc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()#显示图像\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
